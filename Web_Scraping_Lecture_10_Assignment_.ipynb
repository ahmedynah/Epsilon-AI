{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Scraping Lecture 10 Assignment .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNRYL78ncOU8/BMcaRR9md6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahmedynah/Epsilon-AI/blob/main/Web_Scraping_Lecture_10_Assignment_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcJuTMzxa3aA"
      },
      "source": [
        "##Task 1\n",
        "---------\n",
        "#####Scrap the USD To EGP Exchange rate from this website\n",
        "#####https://www.exchangerates.org.uk/Dollars-to-Egyptian-Pounds-currency-conversion-page.html\n",
        "#####and then use it to make a software that takes amount of USD Dollars from the user and calculate how much will it cost in EGP."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYNaJgmIbdEb"
      },
      "source": [
        "import requests\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5fnAoXQaq2e",
        "outputId": "d5dc579f-dea9-43f6-8e14-d72771cd7680"
      },
      "source": [
        "amount = float(input(\"amount in USD: \"))\n",
        "url = 'https://www.exchangerates.org.uk/Dollars-to-Egyptian-Pounds-currency-conversion-page.html'\n",
        "res = requests.get(url)\n",
        "soap = BeautifulSoup(res.text, 'html.parser')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "amount in USD: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCn-ugtycs1q",
        "outputId": "8d9f6321-9ec6-4536-8713-0c2e9931a946"
      },
      "source": [
        "rate = float(soap.find('', attrs = {'id':\"shd2b;\"}).get_text())\n",
        "print(f\"{amount} USD = {amount * rate} EGP\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.0 USD = 78.5005 EGP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msDn7-KcdP1G"
      },
      "source": [
        "Tassk 2\n",
        "---------\n",
        "#####Scrap the weather temperature, humidity, visibility, air pressure, wind speed, datetime data from this website\n",
        "#####https://eg.freemeteo.com/weather/cairo/current-weather/location/?gid=360630&language=english&country=egypt\n",
        "#####for 10 times one read in a minute (so basicly the process takes 10 minutes)and put them into a CSV file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl69JYVxc4pL"
      },
      "source": [
        "def get_weather(url):\n",
        "  \n",
        "  res = requests.get(url)\n",
        "  \n",
        "  soap = BeautifulSoup(res.text, 'html.parser')\n",
        "  temp = soap.find('div', attrs={\"class\": \"temp\"}).get_text()\n",
        "  stats = soap.find('div', attrs={\"class\": \"stats\"}).get_text().replace(\"Rel. \",\"\")\n",
        "  \n",
        "  stats = stats.replace('Few Clouds at 760m',\"\")\n",
        "  stats = stats.replace(\" |\",\"\").splitlines()\n",
        "  \n",
        "  stats_headers, stats_values = [header.strip()for header in stats[0::2]], [value.strip() for value in stats[1::2]]\n",
        "  \n",
        "  stats_headers.insert(0,\"temp\")\n",
        "  stats_values.insert(0,temp)\n",
        "\n",
        "  return stats_headers, stats_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYKxRZf1eNGE"
      },
      "source": [
        "def repeate_every_x_min_for_10_times(x):\n",
        "    with open(\"weather.csv\", \"w\") as f:\n",
        "      url = 'https://eg.freemeteo.com/weather/cairo/current-weather/location/?gid=360630&language=english&country=egypt'\n",
        "      headers, values = get_weather(url)\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerow(headers)\n",
        "      for _ in range(10):\n",
        "         url = 'https://eg.freemeteo.com/weather/cairo/current-weather/location/?gid=360630&language=english&country=egypt'\n",
        "         headers, values = get_weather(url)\n",
        "         writer.writerow(values)\n",
        "    time.sleep(x * 60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td7GO8gakBXa"
      },
      "source": [
        "repeate_every_x_min_for_10_times(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0a2Yl-MwRQG"
      },
      "source": [
        "#Task 3\n",
        "---------\n",
        "#####Scrap the books (name, price, rate) for each category and put them into a CSV file\n",
        "#####https://books.toscrape.com/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYsU1SotweSf"
      },
      "source": [
        "url = 'https://books.toscrape.com/catalogue/category/books_1/index.html'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnIiWsPcEa-Z"
      },
      "source": [
        "res = requests.get(url)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Ld1ql9DTDr"
      },
      "source": [
        "soap = BeautifulSoup(res.text, 'html.parser')\n",
        "index = soap.find('a', attrs={'href':'index.html'})\n",
        "cat_trav = index.find_next_sibling('ul')\n",
        "categories = cat_trav.get_text()\n",
        "categories = categories.split()\n",
        "links_of_each_cat = cat_trav.findAll('li')\n",
        "links_of_each_cat = [link.find('a').get('href').replace(\"..\",'https://books.toscrape.com/catalogue/category')\n",
        " for link in links_of_each_cat]\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdHdkh2qDinz"
      },
      "source": [
        "def get_books_info(link):\n",
        "  res = requests.get(link)\n",
        "  soap = BeautifulSoup(res.text,\"html.parser\")\n",
        "  books = soap.findAll('article', attrs={'class':'product_pod'})\n",
        "  books_info = [\n",
        "     [book.find('h3').find('a').get('title')\n",
        "     ,book.find('p').get('class')[1] + \" stars\"\n",
        "     ,book.find('p',attrs={'class':'price_color'}).get_text().replace(\"Ã‚\",\"\")\n",
        "     ,book.find('h3').find('a').get('href').replace(\"../../..\",\"https://books.toscrape.com/catalogue\")]\n",
        "  for book in books\n",
        "  ]\n",
        "  return books_info"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQ5UB353MGHw"
      },
      "source": [
        "def write_in_csv():\n",
        "  with open(\"books.csv\", \"w\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['Name', 'Rate', \"Price\", \"Link\", \"Category\"])\n",
        "    i = 0\n",
        "    for cat_link in links_of_each_cat:\n",
        "      books = traverse_pages(cat_link)\n",
        "      for book in books:\n",
        "        book.append(categories[i])\n",
        "        writer.writerow(book)\n",
        "      i += 1"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H66gEG0ROP8"
      },
      "source": [
        "def are_there_multiple_pages(link):\n",
        "  res = requests.get(link)\n",
        "  soap = BeautifulSoup(res.text,'html.parser')\n",
        "  multiple_pages = soap.find('ul',attrs={'class':'pager'})\n",
        "  if multiple_pages != None:\n",
        "    number_of_pages = multiple_pages.findAll('li')[0].get_text()\n",
        "    number_of_pages = number_of_pages.strip().split()[-1]\n",
        "    return True, int(number_of_pages), multiple_pages\n",
        "  else:\n",
        "    return False, 0, 0"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-kBcm2NRrob"
      },
      "source": [
        "def get_next_page(link, pager):\n",
        "  next_page = pager.find('li', attrs={'class':'next'}).find('a').get('href')\n",
        "  link = link.replace(\"index.html\",next_page)\n",
        "  return link"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKJiQn-RLD6I"
      },
      "source": [
        "def traverse_pages(link):\n",
        "  \n",
        "  all_books = []\n",
        "  check, no_pages, pager = are_there_multiple_pages(link)\n",
        "  if check:    \n",
        "    for _ in range(no_pages):\n",
        "      all_books.extend(get_books_info(link))\n",
        "      link = get_next_page(link,pager)\n",
        "      res = requests.get(link)\n",
        "      # print(link)\n",
        "  else:\n",
        "    all_books.extend(get_books_info(link))\n",
        "  # print(all_books)\n",
        "  return all_books"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfIyXzMCJxe2"
      },
      "source": [
        "traverse_pages(links_of_each_cat[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUULBDWFJ1lX"
      },
      "source": [
        "write_in_csv()"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gExYaSRSq28P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}